---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluentd
  namespace: default

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fluentd
  namespace: default
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - namespaces
  - nodes
  verbs:
  - get
  - list
  - watch

---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: fluentd
roleRef:
  kind: ClusterRole
  name: fluentd
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: fluentd
  namespace: default
---

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: default
  labels:
    k8s-app: fluentd-logging
    version: v1
spec:
  selector:
    matchLabels:
      k8s-app: fluentd-logging
      version: v1
  template:
    metadata:
      labels:
        k8s-app: fluentd-logging
        version: v1
    spec:
      serviceAccount: fluentd
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch
        env:
          - name:  FLUENT_ELASTICSEARCH_HOST
            value: "elasticsearch-logging"
          - name:  FLUENT_ELASTICSEARCH_PORT
            value: "9200"
          - name: FLUENT_ELASTICSEARCH_SCHEME
            value: "http"
          # Option to configure elasticsearch plugin with self signed certs
          # ================================================================
          - name: FLUENT_ELASTICSEARCH_SSL_VERIFY
            value: "true"
          # Option to configure elasticsearch plugin with tls
          # ================================================================
          - name: FLUENT_ELASTICSEARCH_SSL_VERSION
            value: "TLSv1_2"
          # X-Pack Authentication
          # =====================
          - name: FLUENT_ELASTICSEARCH_USER
            value: "elastic"
          - name: FLUENT_ELASTICSEARCH_PASSWORD
            value: "PaodeMel123##"
          # Logz.io Authentication
          # ======================
          - name: LOGZIO_TOKEN
            value: "ThisIsASuperLongTokenThisIsASuperLongToken"
          - name: LOGZIO_LOGTYPE
            value: "kubernetes"
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        # When actual pod logs in /var/lib/docker/containers, the following lines should be used.
        # - name: dockercontainerlogdirectory
        #   mountPath: /var/lib/docker/containers
        #   readOnly: true
        # When actual pod logs in /var/log/pods, the following lines should be used.
        - name: dockercontainerlogdirectory
          mountPath: /var/log/pods
          readOnly: true
      terminationGracePeriodSeconds: 30
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      # When actual pod logs in /var/lib/docker/containers, the following lines should be used.
      # - name: dockercontainerlogdirectory
      #   hostPath:
      #     path: /var/lib/docker/containers
      # When actual pod logs in /var/log/pods, the following lines should be used.
      - name: dockercontainerlogdirectory
        hostPath:
          path: /var/log/pods


# apiVersion: apps/v1
# kind: DaemonSet
# metadata:
#   name: fluentd
#   namespace: default
#   labels:
#     k8s-app: fluentd-logging
#     version: v1
# spec:
#   selector:
#     matchLabels:
#       k8s-app: fluentd-logging
#       version: v1
#   template:
#     metadata:
#       labels:
#         k8s-app: fluentd-logging
#         version: v1
#     spec:
#       serviceAccount: fluentd
#       serviceAccountName: fluentd
#       tolerations:
#       - key: node-role.kubernetes.io/master
#         effect: NoSchedule
#       containers:
#       - name: fluentd
#         image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch
#         env:
#           - name:  FLUENT_ELASTICSEARCH_HOST
#             value: "elasticsearch-coordinating-only"
#           - name:  FLUENT_ELASTICSEARCH_PORT
#             value: "9200"
#           - name: FLUENT_ELASTICSEARCH_SCHEME
#             value: "http"
#           # Option to configure elasticsearch plugin with self signed certs
#           # ================================================================
#           - name: FLUENT_ELASTICSEARCH_SSL_VERIFY
#             value: "true"
#           # Option to configure elasticsearch plugin with tls
#           # ================================================================
#           - name: FLUENT_ELASTICSEARCH_SSL_VERSION
#             value: "TLSv1_2"
#           # X-Pack Authentication
#           # =====================
#           - name: FLUENT_ELASTICSEARCH_USER
#             value: "elastic"
#           - name: FLUENT_ELASTICSEARCH_PASSWORD
#             value: "PaodeMel123##"
#         resources:
#           limits:
#             memory: 200Mi
#           requests:
#             cpu: 100m
#             memory: 200Mi
#         volumeMounts:
#         - name: varlog
#           mountPath: /var/log
#         - name: dockercontainerlogdirectory
#           mountPath: /var/log/pods
#           readOnly: true
#         - name: elasticsearch-output
#           mountPath: /home/fluentd/
#       terminationGracePeriodSeconds: 30
#       volumes:
#       - name: varlog
#         hostPath:
#           path: /var/log
#       - name: dockercontainerlogdirectory
#         hostPath:
#           path: /var/log/pods
#       - name: elasticsearch-output
#         configMap:
#           name: elasticsearch-output

# ---
# apiVersion: v1
# kind: ConfigMap
# metadata:
#   name: elasticsearch-output
# data:
#   fluent.conf: |

#     # Ignore fluentd own events
#     <match fluent.**>
#       @type null
#     </match>

#     # TCP input to receive logs from the forwarders
#     <source>
#       @type forward
#       bind 0.0.0.0
#       port 24224
#     </source>

#     # HTTP input for the liveness and readiness probes
#     <source>
#       @type http
#       bind 0.0.0.0
#       port 9880
#     </source>

#     # Throw the healthcheck to the standard output instead of forwarding it
#     <match fluentd.healthcheck>
#       @type stdout
#     </match>

#     # Send the logs to the standard output
#     <match **>
#       @type elasticsearch
#       include_tag_key true
#       host "#{ENV['ELASTICSEARCH_HOST']}"
#       port "#{ENV['ELASTICSEARCH_PORT']}"
#       logstash_format true
#       <buffer>
#         @type file
#         path /opt/bitnami/fluentd/logs/buffers/logs.buffer
#         flush_thread_count 2
#         flush_interval 5s
#       </buffer>
#     </match>
